{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install npTDMS to actually pull in the TDMS files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install nptdms\n",
    "!{sys.executable} -m pip install numpy\n",
    "# At least on my system, requirements already satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the tdmsfile reader capabilities from nptdms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time as time\n",
    "import numpy as np\n",
    "from nptdms import TdmsFile\n",
    "from pprint import pprint\n",
    "import os\n",
    "from os import walk\n",
    "import shutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from itertools import chain\n",
    "\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Actually reading things in:\n",
    "\n",
    "The file structure currently isn't really nested the way we want it to be. We need to know:\n",
    "\n",
    "1. How many parts are in our TDMS group.\n",
    "2. How many layers total are in our TDMS group.\n",
    "\n",
    "Ideally, I'd like to be able to work with zipped folders, but there are no guarantees on that one.\n",
    "\n",
    "First goal: Write a method that can find all of our folders witih TDMS files included.\n",
    "\n",
    "Folder needs to have Slice00000#.tdms inside\n",
    "\n",
    "So: \n",
    "Slice000001.tdms\n",
    "Slice000002.tdms\n",
    "Slice000003.tdms ...\n",
    "\n",
    "...\n",
    "Slice00000N.tdms\n",
    "for N slices\n",
    "\n",
    "The result will be a directory called \"NAME, DATE, TDMS Files\"\n",
    "Inside: \n",
    "\\*PART 1 NAME\\*, \\*PHD OR CAMERA\\* TDMS Files\n",
    "\\*PART 2 NAME\\*, \\*PHD OR CAMERA\\* TDMS Files\n",
    "\\*PART 3 NAME\\*, \\*PHD OR CAMERA\\* TDMS Files\n",
    "...\n",
    "\\*PART 1 NAME\\*, \\*PHD OR CAMERA\\* TDMS Files\n",
    "\n",
    "Inside each one of those will be:\n",
    "Slice0001.csv\n",
    "Slice0002.csv\n",
    "...\n",
    "Slice000N.csv\n",
    "\n",
    "For the N slices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter directory path. Forward or backward slash doesn't matter.\n",
      "\n",
      "Example path: C:\\Users\\maxah\\Documents\\CDME\\Sept 9 2019 TDMS Parts\\TDMS\n",
      "/home/maxwell/Documents/CDME/ATRQTestFolder\n",
      "The chosen directory is: /home/maxwell/Documents/CDME/ATRQTestFolder\n",
      "Here are the contents of that directory: \n",
      "\n",
      "['Slice00006.tdms']\n",
      "If that is not the directory you want, hit 'n'. If that is the directory you want, hit 'y'.\n",
      "y\n",
      "What are you going to call this project?\n",
      "EX: \"Nov 21 Build TDMS\"\n",
      "Jan 13 Testing Directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(\"Example directory path: \\nC:/Users/maxah/Documents/CDME/Sept 9 2019 TDMS Parts/TDMS\\n\")\n",
    "testPath = \"C:\\\\Users\\\\maxah\\\\Documents\\\\CDME\\\\Sept 9 2019 TDMS Parts\\\\TDMS\"\n",
    "\n",
    "print(\"Enter directory path. Forward or backward slash doesn't matter.\\n\")\n",
    "\n",
    "time.sleep(.1) #just so that the output makes sense to the user in the correct order; otherwise,\n",
    "#                     the input prompt would come first and be confusing.\n",
    "yesNoChar = 'n'\n",
    "dir_path = \"\"\n",
    "numFiles = 0\n",
    "firstFileName = \"\"\n",
    "while( 'y' not in yesNoChar and 'Y' not in yesNoChar):\n",
    "    \n",
    "    #C:\\\\Users\\\\maxah\\\\Documents\\\\CDME\\\\Sept 9 2019 TDMS Parts\\\\TDMS\n",
    "    #/home/maxwell/Documents/CDME/TestDataATRQ\n",
    "    if(yesNoChar == 'n' or yesNoChar == \"N\"):\n",
    "        dir_path = input(\"Example path: \" + \"C:\\\\Users\\\\maxah\\\\Documents\\\\CDME\\\\Sept 9 2019 TDMS Parts\\\\TDMS\" + \"\\n\")  \n",
    "        if(\"testpath\" in dir_path or \"TESTPATH\" in dir_path):\n",
    "            dir_path = testPath\n",
    "    \n",
    "    #dir_path = testPath\n",
    "    root = os.path.abspath(os.sep)\n",
    "    cwd = Path.cwd()\n",
    "\n",
    "    if('\\\\' in dir_path):\n",
    "        newPath = dir_path.replace(\"\\\\\",\"/\")\n",
    "        dir_path = newPath\n",
    "    \n",
    "    \n",
    "    sourceTDMSDirectory = root / Path(dir_path)        \n",
    "\n",
    "    print(\"The chosen directory is: \" + dir_path)   \n",
    "    \n",
    "    fileNames = []\n",
    "    for (dirpath, dirnames, filenames) in walk(sourceTDMSDirectory):\n",
    "        fileNames.extend(filenames)\n",
    "        break\n",
    "\n",
    "    tdmsFiles = []\n",
    "    for fileName in sorted(fileNames):\n",
    "        if \".tdms_index\" not in fileName:\n",
    "            tdmsFiles.append(fileName)\n",
    "            numFiles = numFiles + 1\n",
    "    print(\"Here are the contents of that directory: \\n\")\n",
    "    length = len(tdmsFiles)\n",
    "    if(length > 0):\n",
    "        firstFileName = tdmsFiles[0]\n",
    "    pprint(tdmsFiles)\n",
    "    \n",
    "    yesNoChar = input(\"If that is not the directory you want, hit 'n'. If that is the directory you want, hit 'y'.\\n\")\n",
    "    \n",
    "print(\"What are you going to call this project?\\nEX: \\\"Nov 21 Build TDMS\\\"\")\n",
    "taskName = \"Processed Stacks \" + input(\"\")\n",
    "sourceTDMSDirectory = Path(dir_path)\n",
    "\n",
    "\"\"\"\n",
    "print(\"What do you want the batch size to be?\\nRecommended values: 5 or 10. Higher batch size means higher memory usage.\")\n",
    "batchSize = int(input(\"Please enter a number: \"))\n",
    "\n",
    "\"\"\"\n",
    "batchSize = 1\n",
    "\n",
    "firstSliceNum = firstFileName[-6:-5]\n",
    "#C:\\\\Users\\\\maxah\\\\Documents\\\\CDME\\\\Sept 9 2019 TDMS Parts\\\\TDMS\n",
    "#/home/maxwell/Documents/CDME/TestDataATRQ\n",
    "# /home/maxwell/Documents/CDME/ATRQTestFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filepath now stored. \n",
    "\n",
    "Filepath is now stored and we have a handy dandy conversion from Windows file structure to a python readable format.\n",
    "Let's create a list of everything in the directory.\n",
    "\n",
    "Any \".tdms_index\" files are created by using the National Instruments' \"TDMS To Excel\" tool, and can be ignored.\n",
    "They will just be removed from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build directories was 3.292267322540283 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a map of the file names to new file locations; \n",
    "\n",
    "#Make a \"Processed\" directory as a subdirectory one folder up\n",
    "\n",
    "directoryBuildTime = time.time()\n",
    "#sourceTDMSDirectory is where we are collecting these files\n",
    "\n",
    "# I know these parentheses are ugly, but lemme explain.\n",
    "#TdmsFile only takes a string, but I want it to work on Linux or Windows. So I'm using the Path library\n",
    "# to concatenate these strings together in a way that works on both OS's. \n",
    "#   The Path lib takes a \"/\" as an operator to concatenate filepaths.\n",
    "# Then, after I concatenate the paths, I turn them back into a string.\n",
    "firstObject = TdmsFile(str(Path(str(sourceTDMSDirectory)) / Path(str(tdmsFiles[0]))))\n",
    "\n",
    "parentDir = sourceTDMSDirectory.parent\n",
    "newFolder = parentDir / str(taskName)\n",
    "newFolder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "#Now that we have the folder: let's go in and make a subfolder for every group we've got in the TDMS files.\n",
    "FolderDictionary = dict()\n",
    "groups = firstObject.groups()\n",
    "for part in groups:\n",
    "    folderName = str(part)\n",
    "    newDir = newFolder / folderName\n",
    "    newDir.mkdir(exist_ok=True, parents=True)\n",
    "    #print(\"\\n \\n\" + str(part) + \" \\n\" + str(newDir))\n",
    "    \n",
    "    FolderDictionary[str(part)] = str(newDir)\n",
    "    \n",
    "#pprint(FolderDictionary)\n",
    "#Boom: we've now got a folder for every part, and a mapping of group name (part name) to folder name.\n",
    "\n",
    "#Next step is to go into every TDMS's item, and write the\n",
    "#associated data to a CSV inside of the folder for that name, with a good name for the slice.\n",
    "#sourceTDMSDirectory\n",
    "\n",
    "directoryBuildTime = time.time() - directoryBuildTime\n",
    "print(\"Time to build directories was \" + str(directoryBuildTime) + \" seconds.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "IndexError. Possibly no data for that part anymore?\n",
      "While writing file: /home/maxwell/Documents/CDME/Processed Stacks Jan 13 Testing Directory/1_00048_op2_pole_s_cls/Slice0006.csv\n",
      "\n",
      "IndexError. Possibly no data for that part anymore?\n",
      "While writing file: /home/maxwell/Documents/CDME/Processed Stacks Jan 13 Testing Directory/1_00048_op2_pole_s_cls/Slice0006.csv\n",
      "\n",
      "IndexError. Possibly no data for that part anymore?\n",
      "While writing file: /home/maxwell/Documents/CDME/Processed Stacks Jan 13 Testing Directory/0_00089_op1_ATRQ_25mm_triangle_s_2_cls/Slice0006.csv\n",
      "\n",
      "\n",
      "Time for this batch was 8.270381927490234 seconds.\n",
      "Or 8.270381927490234 seconds per layer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(str(sourceTDMSDirectory) + \"\\\\\" + tdmsFiles[0])\n",
    "#testTime = time.time()\n",
    "openedSoFar = 0\n",
    "numLayers = 0\n",
    "tdmsObjects = []\n",
    "numBatches = 0\n",
    "populatedList = set()\n",
    "sliceCounter = int(firstSliceNum) - 1\n",
    "#Outermost loop: controls the number of files written, total.\n",
    "while numLayers < numFiles:\n",
    "    \n",
    "    #Gets files from TDMS files\n",
    "    #   This one isn't the outermost because I want to manage memory better.\n",
    "    for file in tdmsFiles:\n",
    "        \n",
    "        #opens a TDMS file. Doing the same weird path-trick as before, to be OS independent.\n",
    "        tdmsObjects.append( TdmsFile( str( Path(str(sourceTDMSDirectory)) / Path(str(file)) ) ) )\n",
    "        numLayers+=1\n",
    "        \n",
    "        #Once we've got a few of the TDMS files open, transform them into CSV's.\n",
    "        #   Happens every time a batch is fill (IE: every 5th file)\n",
    "        if(numLayers % batchSize == 0 or numLayers == numFiles):\n",
    "            \n",
    "            #all of the actual file writing will happen in here\n",
    "            \n",
    "            processTime = time.time()\n",
    "            #print(\"Block \" + str(numBatches))\n",
    "            #print(str(tdmsObjects) + \"\\n\")\n",
    "            \n",
    "            \n",
    "            colNames = []\n",
    "            populatedList = set()\n",
    "            \n",
    "            #print(tdmsObjects)\n",
    "            #print(numLayers)\n",
    "            \n",
    "            for tdms in tdmsObjects:\n",
    "                sliceCounter = sliceCounter + 1\n",
    "                groups = tdms.groups()\n",
    "                #print(tdms)\n",
    "                for part in groups:\n",
    "                    #get the data from each group's channel and make a CSV\n",
    "                    channels = tdms.group_channels(part)\n",
    "        \n",
    "        \n",
    "                    #make a 2D array, and populate it with the arrays in this loop.\n",
    "                    groupCSV = []\n",
    "                    areaCol = []\n",
    "                    xCol = []\n",
    "                    yCol = []\n",
    "                    paramCol = []\n",
    "                    intensityCol = []\n",
    "                    laserCol = []\n",
    "                    csvCount = 0\n",
    "                    #copy each channel's data to its respective frame\n",
    "        \n",
    "                    for channel in channels:\n",
    "            \n",
    "                        names = []\n",
    "                        for i in channels:\n",
    "                            wordList = str(i).split(\"/\")\n",
    "                            name = wordList[-1]\n",
    "                            name = name.strip(\">\")\n",
    "                            name = name.strip(\"'\")\n",
    "                            names.append(name)\n",
    "                        colNames = names    \n",
    "                        #pprint(channel.data)\n",
    "                        name = channel.channel\n",
    "                        data = channel.data\n",
    "            \n",
    "                        if(names[0] in name):\n",
    "                            areaCol = data\n",
    "                        elif(names[1] in name):\n",
    "                            xCol = data\n",
    "                        elif(names[2] in name):\n",
    "                            yCol = data\n",
    "                        elif(names[3] in name):\n",
    "                            paramCol = data\n",
    "                        elif(names[4] in name):\n",
    "                            intensityCol = data\n",
    "                        elif(names[5] in name):\n",
    "                            laserCol = data\n",
    "                        groupCSV.append(data)\n",
    "                        csvCount += 1\n",
    "            \n",
    "                    csvFileLocation = FolderDictionary[str(part)]\n",
    "                \n",
    "                    #I tried avoiding this earlier, but here I'm just checking the os. If unix, then use\n",
    "                    #  the unix file delimiter (forwardslash). If windows, then use the backslash delimiter.\n",
    "                    if(os.name is \"posix\"):\n",
    "                        sliceFileName = str(csvFileLocation) + \"/Slice000\" + str(sliceCounter) + \".csv\"\n",
    "                    elif(os.name is \"nt\"):\n",
    "                        sliceFileName = str(csvFileLocation) + \"\\\\Slice000\" + str(sliceCounter) + \".csv\"\n",
    "                        \n",
    "                    \n",
    "                    with open(sliceFileName, mode=\"w\", newline = \"\") as csvfile:\n",
    "                        wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL, dialect=\"excel\")\n",
    "                        wr.writerow(names)\n",
    "                        \n",
    "                        #if len(areaCol) > 1 means:\n",
    "                        #if there are data points in here\n",
    "                        # But what if there straight up aren't any columns to begin with??\n",
    "                        \n",
    "                        # IN that case then I need to identify if there are no rows\n",
    "                        \n",
    "                        if(len(areaCol > 1)):\n",
    "                            for rows in range(0,len(areaCol - 1) ):#- 1):\n",
    "                                #print(str(len(areaCol)) + \"\\n\")\n",
    "                                \n",
    "                                # THIS IS A PROBLEM LINE\n",
    "                                # With this line: I need to check if there are things here,\n",
    "                                #   and not write the row if that's the case.\n",
    "                                # Alternative: a try / catch on this bad boy?\n",
    "                                \n",
    "                                try:\n",
    "                                    #print(\"Writing file: \" + str(sliceFileName) + \"\\n\")\n",
    "                                    row = [areaCol[rows], xCol[rows], yCol[rows], paramCol[rows], intensityCol[rows], laserCol[rows]]\n",
    "                                    wr.writerow(row)\n",
    "                                except IndexError: \n",
    "                                    print(\"IndexError. Possibly no data for that part anymore?\")\n",
    "                                    print(\"While writing file: \" + str(sliceFileName) + \"\\n\")\n",
    "                            populatedList.add(part)\n",
    "                \n",
    "            \n",
    "            processTime = time.time() - processTime\n",
    "            print(\"\\nTime for this batch was \" + str(processTime) + \" seconds.\")\n",
    "            print(\"Or \" + str(processTime / (sliceCounter - int(firstSliceNum) + 1)) + \" seconds per layer.\\n\")\n",
    "\n",
    "            \n",
    "            #end operation space\n",
    "            #this declaration clears the memory for the tdms objects\n",
    "            tdmsObjects = []\n",
    "            numBatches = numBatches + 1\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "#endTime = time.time()\n",
    "\n",
    "#timeLength = endTime - testTime\n",
    "#this block takes roughly 13.49 seconds on my machine -- \n",
    "#print(\"All TDMS objects read in, took \" + str(timeLength) + \" seconds.\\n\" + str((timeLength)/5) + \" seconds per layer.\\n\")\n",
    "#or roughly 2.7 seconds per layer. That isn't ideal, \n",
    "#since it's the price we can stand to pay for every access of a TDMS object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time information:\n",
    "It's taking roughly 30 seconds per layer, but that's probably pretty variable.\n",
    "If you want to do 800 layers then, we're looking at 2400 seconds or 40 minutes.\n",
    "This might be the kind of script you set up and run and leave overnight once it's finished.\n",
    "Speed may also depend on the computer it's being performed on -- the slowdown is likely the read/writes happening, so the \n",
    "hard disk in the desktops here at the CDME could be slower than my machine's SSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(start_path = '.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "\n",
    "    return total_size\n",
    "\n",
    "def count_files(start_path = \".\"):\n",
    "    total_files = 0\n",
    "    return(len(os.listdir(start_path)))\n",
    "    \n",
    "\n",
    "#print(get_size(), 'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "\n",
      "{'0_00004_op1_Pad_2_s_4_cls',\n",
      " '0_00005_op1_Pad_3_s_7_cls',\n",
      " '0_00047_op1_pole_s_cls',\n",
      " '0_00089_op1_ATRQ_25mm_triangle_s_2_cls',\n",
      " '0_00119_op1_Pad_4_s_5_cls',\n",
      " '0_00207_op1_Pad_1_s_2_cls',\n",
      " '1_00006_op2_Pad_4_s_8_cls',\n",
      " '1_00048_op2_pole_s_cls',\n",
      " '1_00109_op2_Pad_1_s_cls',\n",
      " '1_00145_op2_ATRQ_25mm_triangle_s_cls',\n",
      " '1_00205_op2_Pad_3_s_3_cls',\n",
      " '1_00206_op2_Pad_2_s_6_cls'}\n",
      "\n",
      "***FINISHED REPORT***\n",
      "\n",
      "Runtime was: 445.1254494190216 seconds.\n",
      "Number of layers written was: 1 layers.\n",
      "Number of parts with no data was: 474 parts.\n",
      "Number of parts with data was: 12 parts.\n",
      "Parts with data: \n",
      "Finished: type the X key to exit.X\n"
     ]
    }
   ],
   "source": [
    "partsDeleted = 0\n",
    "partsRemaining = 0\n",
    "for k, v in FolderDictionary.items():\n",
    "    byteSize = get_size(v)\n",
    "    fileCount = count_files(v)\n",
    "    minimumBytes = 62 * int(fileCount) #61 is the number of bytes contained in the headers.\n",
    "    #If a folder has less than 62 bytes per file, then delete the folder.\n",
    "    #Note: if there are some empty files in a folder, leave the entire thing for now.\n",
    "    if (byteSize < minimumBytes):\n",
    "        #delete the directory v, since many of the folders don't actually contain any data\n",
    "        partsDeleted = partsDeleted + 1\n",
    "        shutil.rmtree(v)\n",
    "    else:\n",
    "        partsRemaining = partsRemaining + 1\n",
    "\n",
    "# Boom: now it only keeps those which have items inside.\n",
    "print(\"Finished.\\n\")\n",
    "pprint(populatedList)\n",
    "        \n",
    "endTime = time.time()\n",
    "runTime = endTime - startTime\n",
    "print(\"\\n***FINISHED REPORT***\")\n",
    "print(\"\\n\" + \"Runtime was: \" + str(runTime) + \" seconds.\")\n",
    "print(\"Number of layers written was: \" + str(numLayers) + \" layers.\")\n",
    "print(\"Number of parts with no data was: \" + str(partsDeleted) + \" parts.\")\n",
    "print(\"Number of parts with data was: \" + str(partsRemaining) + \" parts.\")\n",
    "print(\"Parts with data: \")\n",
    "\n",
    "#input hold; causes the program to freeze before exiting.\n",
    "exit = input(\"Finished: type the X key to exit.\")\n",
    "time.sleep(.01)\n",
    "if(\"x\" not in exit and \"X\" not in exit):\n",
    "    input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
